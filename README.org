#+TITLE: 25th IEEE Symposium on Computers and Communications (ISCC) 2020
#+AUTHOR: Anderson M. Maliszewski
#+STARTUP: overview indent
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

This repository is for the *25th IEEE Symposium on Computers and
Communications (ISCC) 2020* paper, and has the entire project used to
perform it. Below are the files and folders, along with the analysis
environment and references. More details on how to reproduce the
experiments are in [[LabBook.org]].

#+BEGIN_QUOTE
*Reporting errors*: This repository has several links to self-contained
 files as well as links from the Internet, so if you try to reproduce
 it and find broken links or other problems, please tell me everything
 so that I can improve it. :)
#+END_QUOTE

* Folders and Files Description
- [[BENCHMARKS]] - This folder has all the benchmarks (Alya, Intel MPI
  Benchmarks and NAS Parallel Benchmarks).
- [[LabBook.org]] - In this file is described the entire experimental
  project, with the objective, benchmarks, how to reproduce it,
  software installation, system information, network information,
  design of experiments, bash script description, experiments
  execution, and finally the graphical analysis.
- [[LOGS]] - This folder has the benchmark execution logs in CSV files
  (~apps_exec~ and ~intel~), a file containing the [[LOGS/env_info.org][environment information]]
  used in the experiments, a folder called [[LOGS/LOGS_BACKUP][LOGS_BACKUP]] that includes
  the application logs without any modification, a folder called
  [[LOGS/LOGS_BACKUP_SRC_ODE][LOGS_BACKUP_SRC_CODE]] that has the source code of the benchmarks, and a
  folder called [[LOGS/LOGS_DOWNLOAD][LOGS_DOWNLOAD]] with the software download logs.
- [[SH/MACHINE_FILES][MACHINE_FILES]] - In this folder are the two machine files ([[LOGS/nodes][nodes]] and
  [[LOGS/nodes_intel][nodes_intel]] used by the MPI execution line.
- [[SH]] - Here are the bash scripts ([[SH/experiments_exec.sh][experiments_exec]], [[SH/central.sh][central]],
  [[SH/clean_folders_files.sh][clean_folder_files]], [[SH/software_install.sh][software_install]], and [[SH/sys_info_collect.sh][sys_info_collect]]) that are
  used to perform the experiments and collect system information.

* Analysis Environment 
Some specific softwares are required to reproduce this evaluation
accurately. They are Emacs and Org, both used as project management
tools to track, record all information, and generate graphics using R
code blocks. A complete tutorial on how to install and configure the
mentioned softwares is available [[https://app-learninglab.inria.fr/gitlab/learning-lab/mooc-rr-ressources/blob/master/module2/ressources/emacs_orgmode.org][here]]. If you do not want to use this
softwares, you can copy the blocks of code and use R or RStudio to
generate the graphics.
 
* References
+ R. Jain, [[http://www.cs.wustl.edu/~jain/books/perfbook.htm][The Art of Computer Systems Performance Analysis:
  Techniques for Experimental Design, Measurement, Simulation, and
  Modeling]], Wiley-Interscience, New York, NY, April 1991.
#+BEGIN_QUOTE
This was the base book used in the *CMP223 - Computer System
Performance Analysis (2019/2)* discipline and can be considered the
oracle for creating performance evaluations even though it is old, but
the checklists and concepts are still current today.
#+END_QUOTE
+ Legrand. Arnaud, Schnorr. Lucas, [[https://github.com/alegrand/SMPE.git][Scientific Methodology and
  Performance Evaluation for Computer Scientists]], GitHub Repository.
#+BEGIN_QUOTE
In this repository is a course called *Scientific Methodology and
Performance Evaluation for Computer Scientists*, based on several
renowned books (including Jain's). The aim is to provide the
fundamental basis for a sound scientific methodology for performance
evaluation of computer systems.
#+END_QUOTE

